{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCzzxAnFpJRT+hdBBFgSe1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielmancovidales/Aplicaciones-en-salud/blob/main/tuneo_hiperp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXukKNcTuJcT",
        "outputId": "43446e07-3267-493b-d075-e888d8f22962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "# Librerias generales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYgwGLIVuR2-",
        "outputId": "1bc1dc1b-b3b3-4228-c3c3-c8fca84fa3c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura de base de datos\n",
        "df = pd.read_csv('/content/drive/MyDrive/analitica3/Salud/df_sel.csv')\n",
        "y = pd.read_csv('/content/drive/MyDrive/analitica3/Salud/y.csv')\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "y.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "woUGsCA1uYF9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Escalado de la variable target\n",
        "scaler = MinMaxScaler()\n",
        "y['tiempo_estancia'] = scaler.fit_transform(y[['tiempo_estancia']])"
      ],
      "metadata": {
        "id": "kpHW3-anumZL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separacion de datos\n",
        "X_train,X_test,y_train,y_test=train_test_split(df,y,test_size=0.3,random_state=0)"
      ],
      "metadata": {
        "id": "Xmwza_9nuuxK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <h1> LGBMRegressor"
      ],
      "metadata": {
        "id": "WeiQnT3zuxA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tuneo**"
      ],
      "metadata": {
        "id": "zy5MSQWnvJd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"n_estimators\": 1000,\n",
        "        \"verbosity\": -1,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
        "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.001, 1.0, log=True)  # Agrega la regularización L1\n",
        "    }\n",
        "    model = lgb.LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "objKyBmau6St"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOej7skHvAjF",
        "outputId": "dae0d29c-1189-4eab-c191-6b63913a6b16"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-07 06:40:04,688] A new study created in memory with name: no-name-bf6f6903-b82b-4eab-8210-9cb098b82263\n",
            "[I 2024-05-07 06:40:05,599] Trial 0 finished with value: 0.0713968713961589 and parameters: {'learning_rate': 0.0010335467151415744, 'num_leaves': 249, 'subsample': 0.47821834338646835, 'colsample_bytree': 0.2458061834831447, 'min_data_in_leaf': 43, 'reg_alpha': 0.12306484298063528}. Best is trial 0 with value: 0.0713968713961589.\n",
            "[I 2024-05-07 06:40:06,244] Trial 1 finished with value: 0.07356561144892099 and parameters: {'learning_rate': 0.08801873940450644, 'num_leaves': 207, 'subsample': 0.9476201240238571, 'colsample_bytree': 0.18853610225807477, 'min_data_in_leaf': 71, 'reg_alpha': 0.010938960115638286}. Best is trial 0 with value: 0.0713968713961589.\n",
            "[I 2024-05-07 06:40:07,323] Trial 2 finished with value: 0.06502016659090612 and parameters: {'learning_rate': 0.0015238723525740937, 'num_leaves': 51, 'subsample': 0.7465166127928877, 'colsample_bytree': 0.767671850262405, 'min_data_in_leaf': 31, 'reg_alpha': 0.13397544138896783}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:07,918] Trial 3 finished with value: 0.0725994062343531 and parameters: {'learning_rate': 0.05153356454724131, 'num_leaves': 318, 'subsample': 0.35921104226115647, 'colsample_bytree': 0.6738781593079572, 'min_data_in_leaf': 46, 'reg_alpha': 0.023852022377818284}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:09,273] Trial 4 finished with value: 0.06729932889924072 and parameters: {'learning_rate': 0.011563474938378211, 'num_leaves': 747, 'subsample': 0.7231010140773532, 'colsample_bytree': 0.4937212695717963, 'min_data_in_leaf': 29, 'reg_alpha': 0.011717717766029635}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:09,616] Trial 5 finished with value: 0.07367458697090758 and parameters: {'learning_rate': 0.0010827659911444108, 'num_leaves': 368, 'subsample': 0.483049436468954, 'colsample_bytree': 0.09263328451624944, 'min_data_in_leaf': 66, 'reg_alpha': 0.14894631527707083}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:10,083] Trial 6 finished with value: 0.0653621271760132 and parameters: {'learning_rate': 0.0012905161746502732, 'num_leaves': 542, 'subsample': 0.8325387847990517, 'colsample_bytree': 0.7423571393537627, 'min_data_in_leaf': 63, 'reg_alpha': 0.13739481430133535}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:10,871] Trial 7 finished with value: 0.06524264296292184 and parameters: {'learning_rate': 0.001246716379818341, 'num_leaves': 967, 'subsample': 0.9604798514755022, 'colsample_bytree': 0.7037898726088289, 'min_data_in_leaf': 39, 'reg_alpha': 0.20674270539525513}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:11,265] Trial 8 finished with value: 0.06898487024272419 and parameters: {'learning_rate': 0.015235837663155071, 'num_leaves': 990, 'subsample': 0.8568731886087441, 'colsample_bytree': 0.1837376671594667, 'min_data_in_leaf': 97, 'reg_alpha': 0.0014543445738968213}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:11,893] Trial 9 finished with value: 0.06561225970603946 and parameters: {'learning_rate': 0.00235372129617851, 'num_leaves': 693, 'subsample': 0.3061410783123394, 'colsample_bytree': 0.9576904044645955, 'min_data_in_leaf': 22, 'reg_alpha': 0.05572013569457791}. Best is trial 2 with value: 0.06502016659090612.\n",
            "[I 2024-05-07 06:40:12,191] Trial 10 finished with value: 0.06494785925803569 and parameters: {'learning_rate': 0.004099033386030208, 'num_leaves': 3, 'subsample': 0.6857866715419491, 'colsample_bytree': 0.9801162163439889, 'min_data_in_leaf': 13, 'reg_alpha': 0.5721226886098292}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:12,567] Trial 11 finished with value: 0.06931864365531619 and parameters: {'learning_rate': 0.003465451218052573, 'num_leaves': 28, 'subsample': 0.09213102385790484, 'colsample_bytree': 0.9952191673554914, 'min_data_in_leaf': 1, 'reg_alpha': 0.8769422328959189}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:13,280] Trial 12 finished with value: 0.06562617633914862 and parameters: {'learning_rate': 0.005849944344585474, 'num_leaves': 19, 'subsample': 0.6687572800714141, 'colsample_bytree': 0.8455669708822163, 'min_data_in_leaf': 10, 'reg_alpha': 0.9043258410547718}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:14,011] Trial 13 finished with value: 0.06509261368731258 and parameters: {'learning_rate': 0.003599581668260375, 'num_leaves': 142, 'subsample': 0.6676310368738427, 'colsample_bytree': 0.5533440167446315, 'min_data_in_leaf': 21, 'reg_alpha': 0.7181772185990224}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:15,080] Trial 14 finished with value: 0.0661500234692756 and parameters: {'learning_rate': 0.006154988654224277, 'num_leaves': 460, 'subsample': 0.603757793852615, 'colsample_bytree': 0.8497256906779774, 'min_data_in_leaf': 12, 'reg_alpha': 0.277861955427698}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:15,775] Trial 15 finished with value: 0.06827952912559115 and parameters: {'learning_rate': 0.02011164138288794, 'num_leaves': 106, 'subsample': 0.7838148996213562, 'colsample_bytree': 0.8567597322719052, 'min_data_in_leaf': 32, 'reg_alpha': 0.35723334910772914}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:17,866] Trial 16 finished with value: 0.06668126042927101 and parameters: {'learning_rate': 0.0025638600947452623, 'num_leaves': 137, 'subsample': 0.5673353453923149, 'colsample_bytree': 0.48745632694472946, 'min_data_in_leaf': 4, 'reg_alpha': 0.04819554990490176}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:18,248] Trial 17 finished with value: 0.06797535494010677 and parameters: {'learning_rate': 0.00658321408515987, 'num_leaves': 7, 'subsample': 0.3629769246565901, 'colsample_bytree': 0.6330076964854334, 'min_data_in_leaf': 53, 'reg_alpha': 0.4114730299231889}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:19,446] Trial 18 finished with value: 0.06588309292764383 and parameters: {'learning_rate': 0.0018946887606077886, 'num_leaves': 445, 'subsample': 0.7731477327918798, 'colsample_bytree': 0.34319361362267725, 'min_data_in_leaf': 18, 'reg_alpha': 0.001947977558941266}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:20,969] Trial 19 finished with value: 0.06525624723024001 and parameters: {'learning_rate': 0.004062793070274533, 'num_leaves': 631, 'subsample': 0.8726062716626946, 'colsample_bytree': 0.9143751436262507, 'min_data_in_leaf': 33, 'reg_alpha': 0.06162901673408124}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:21,151] Trial 20 finished with value: 0.0762981719286476 and parameters: {'learning_rate': 0.001863642147758947, 'num_leaves': 272, 'subsample': 0.07400599051750184, 'colsample_bytree': 0.7718186358253798, 'min_data_in_leaf': 82, 'reg_alpha': 0.00425283345556501}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:22,108] Trial 21 finished with value: 0.0650582779549837 and parameters: {'learning_rate': 0.003792764132389338, 'num_leaves': 121, 'subsample': 0.6752199971443102, 'colsample_bytree': 0.5756861664429375, 'min_data_in_leaf': 22, 'reg_alpha': 0.6050867608692364}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:23,183] Trial 22 finished with value: 0.0659090837856429 and parameters: {'learning_rate': 0.007927850229626155, 'num_leaves': 111, 'subsample': 0.678271088196211, 'colsample_bytree': 0.5925385613332985, 'min_data_in_leaf': 22, 'reg_alpha': 0.53617841306854}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:24,092] Trial 23 finished with value: 0.06570553395786792 and parameters: {'learning_rate': 0.004655282365000793, 'num_leaves': 180, 'subsample': 0.5955253953470621, 'colsample_bytree': 0.4071282390051529, 'min_data_in_leaf': 12, 'reg_alpha': 0.27047959898902824}. Best is trial 10 with value: 0.06494785925803569.\n",
            "[I 2024-05-07 06:40:24,587] Trial 24 finished with value: 0.06434857099737479 and parameters: {'learning_rate': 0.0026451215825294186, 'num_leaves': 72, 'subsample': 0.7288439007414641, 'colsample_bytree': 0.7855536254656119, 'min_data_in_leaf': 55, 'reg_alpha': 0.09402913388021308}. Best is trial 24 with value: 0.06434857099737479.\n",
            "[I 2024-05-07 06:40:25,149] Trial 25 finished with value: 0.0646568166700571 and parameters: {'learning_rate': 0.0018653170568841305, 'num_leaves': 364, 'subsample': 0.7640281914722683, 'colsample_bytree': 0.7883753335902591, 'min_data_in_leaf': 51, 'reg_alpha': 0.07093021254659897}. Best is trial 24 with value: 0.06434857099737479.\n",
            "[I 2024-05-07 06:40:25,843] Trial 26 finished with value: 0.06457626056591663 and parameters: {'learning_rate': 0.0026909166634352917, 'num_leaves': 374, 'subsample': 0.9012353313628261, 'colsample_bytree': 0.9245995913344738, 'min_data_in_leaf': 55, 'reg_alpha': 0.026614989852652125}. Best is trial 24 with value: 0.06434857099737479.\n",
            "[I 2024-05-07 06:40:26,575] Trial 27 finished with value: 0.06461186986790167 and parameters: {'learning_rate': 0.002623160367450442, 'num_leaves': 384, 'subsample': 0.9871557851893051, 'colsample_bytree': 0.8348016010149247, 'min_data_in_leaf': 54, 'reg_alpha': 0.020072806138537184}. Best is trial 24 with value: 0.06434857099737479.\n",
            "[I 2024-05-07 06:40:27,303] Trial 28 finished with value: 0.06452608617033789 and parameters: {'learning_rate': 0.002654990890098206, 'num_leaves': 851, 'subsample': 0.9778452953489717, 'colsample_bytree': 0.8904407920202047, 'min_data_in_leaf': 57, 'reg_alpha': 0.020673744480521686}. Best is trial 24 with value: 0.06434857099737479.\n",
            "[I 2024-05-07 06:40:27,867] Trial 29 finished with value: 0.07089308560529899 and parameters: {'learning_rate': 0.02504981078615873, 'num_leaves': 880, 'subsample': 0.9098163928753356, 'colsample_bytree': 0.9326797640513853, 'min_data_in_leaf': 79, 'reg_alpha': 0.010411176246717476}. Best is trial 24 with value: 0.06434857099737479.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best hyperparameters:', study.best_params)\n",
        "print('Best RMSE:', study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWm2ZLuvvDcc",
        "outputId": "7bf3b310-1dc3-45a4-ae5f-a3bdaa59cbbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'learning_rate': 0.0026451215825294186, 'num_leaves': 72, 'subsample': 0.7288439007414641, 'colsample_bytree': 0.7855536254656119, 'min_data_in_leaf': 55, 'reg_alpha': 0.09402913388021308}\n",
            "Best RMSE: 0.06434857099737479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Modelo**"
      ],
      "metadata": {
        "id": "0d4TmxzQvQ6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creacion modelo LGBMRegressor\n",
        "m_lgb=lgb.LGBMRegressor(learning_rate=0.0026451215825294186, num_leaves=72, subsample= 0.7288439007414641, colsample_bytree= 0.7855536254656119, min_data_in_leaf= 55, reg_alpha= 0.09402913388021308)\n",
        "m_lgb.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J3oZ0yXzvIQ9",
        "outputId": "ded1acea-9dad-4d75-9a50-feea3d8882af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2652\n",
            "[LightGBM] [Info] Number of data points in the train set: 906, number of used features: 55\n",
            "[LightGBM] [Info] Start training from score 0.083391\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(colsample_bytree=0.7855536254656119,\n",
              "              learning_rate=0.0026451215825294186, min_data_in_leaf=55,\n",
              "              num_leaves=72, reg_alpha=0.09402913388021308,\n",
              "              subsample=0.7288439007414641)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.7855536254656119,\n",
              "              learning_rate=0.0026451215825294186, min_data_in_leaf=55,\n",
              "              num_leaves=72, reg_alpha=0.09402913388021308,\n",
              "              subsample=0.7288439007414641)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.7855536254656119,\n",
              "              learning_rate=0.0026451215825294186, min_data_in_leaf=55,\n",
              "              num_leaves=72, reg_alpha=0.09402913388021308,\n",
              "              subsample=0.7288439007414641)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Supongamos que ya has ajustado tu modelo y tienes los conjuntos de datos de entrenamiento y prueba\n",
        "# X_train, X_test, y_train, y_test representan tus datos\n",
        "\n",
        "# Entrenar tu modelo con X_train y y_train\n",
        "\n",
        "# Realizar predicciones en el conjunto de entrenamiento\n",
        "y_pred_train = m_lgb.predict(X_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_test = m_lgb.predict(X_test)\n",
        "\n",
        "# Desescalar los valores predichos y los valores reales tanto para entrenamiento como para prueba\n",
        "y_train_o = scaler.inverse_transform(y_train)\n",
        "y_pred_train = y_pred_train.reshape(-1, 1)\n",
        "y_pred_train_o = scaler.inverse_transform(y_pred_train)\n",
        "\n",
        "y_test_o = scaler.inverse_transform(y_test)\n",
        "y_pred_test = y_pred_test.reshape(-1, 1)\n",
        "y_pred_test_o = scaler.inverse_transform(y_pred_test)\n",
        "\n",
        "# Calcular métricas R^2, MAE y RMSE para el conjunto de entrenamiento\n",
        "r2_train = r2_score(y_train_o, y_pred_train_o)\n",
        "mae_train = mean_absolute_error(y_train_o, y_pred_train_o)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train_o, y_pred_train_o))\n",
        "\n",
        "# Calcular métricas R^2, MAE y RMSE para el conjunto de prueba\n",
        "r2_test = r2_score(y_test_o, y_pred_test_o)\n",
        "mae_test = mean_absolute_error(y_test_o, y_pred_test_o)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test_o, y_pred_test_o))\n",
        "\n",
        "# Imprimir los resultados para el conjunto de entrenamiento\n",
        "\n",
        "print(\"Train - MAE:\", mae_train)\n",
        "print(\"Train - RMSE:\", rmse_train)\n",
        "\n",
        "\n",
        "# Imprimir los resultados para el conjunto de prueba\n",
        "\n",
        "print(\"Test - MAE:\", mae_test)\n",
        "print(\"Test - RMSE:\", rmse_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0BP6i1JvXIC",
        "outputId": "6643b427-59bd-44fd-c5e2-038349041538"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=55, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55\n",
            "Train - MAE: 122.37282926154037\n",
            "Train - RMSE: 192.1954110045669\n",
            "Test - MAE: 116.24780854010542\n",
            "Test - RMSE: 164.53630241813036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**\n",
        "\n",
        "**Antes del tuneo:** Los valores bajos de MAE y RMSE en el conjunto de entrenamiento indicaban que el modelo aprendía patrones de los datos de entrenamiento de manera efectiva.\n",
        "\n",
        "**Después del tuneo:** Un aumento significativo en MAE y RMSE sugiere que el tuneo de hiperparámetros podría haber causado un sobreajuste del modelo en los datos de entrenamiento. Esto significa que el modelo ahora se adapta demasiado a los detalles específicos del conjunto de entrenamiento y no generaliza bien a nuevos datos no vistos.\n",
        "\n",
        "**Test**\n",
        "\n",
        "**Antes del tuneo:** Los valores de MAE y RMSE en el conjunto de prueba eran razonables, lo que indica que el modelo tenía una capacidad decente de generalización a datos no vistos.\n",
        "\n",
        "**Después del tuneo:** Un ligero aumento en MAE y RMSE en el conjunto de prueba sugiere que el tuneo de hiperparámetros no tuvo un impacto significativo en la capacidad de generalización del modelo."
      ],
      "metadata": {
        "id": "68sz2PJ7zNdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusiones**"
      ],
      "metadata": {
        "id": "2y9J-3pJzolD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-El tuneo de hiperparámetros no ha logrado mejorar el rendimiento del modelo en términos de error de entrenamiento o generalización.\n",
        "\n",
        "-El modelo podría estar sobreajustado a los datos de entrenamiento después del tuneo de hiperparámetros.\n",
        "\n",
        "-Es posible que los hiperparámetros seleccionados no sean adecuados para el problema específico.\n",
        "\n",
        "-Los datos quizá no aporten mucho a la explicación de la variable objetivo.\n",
        "\n",
        "-Para futuros estudios se podría optar por dejar muchas más variables y probar otros modelos ya que la misma naturaleza continua de la variable target hace que sea más compleja su predicción."
      ],
      "metadata": {
        "id": "voZliu5-zxl3"
      }
    }
  ]
}